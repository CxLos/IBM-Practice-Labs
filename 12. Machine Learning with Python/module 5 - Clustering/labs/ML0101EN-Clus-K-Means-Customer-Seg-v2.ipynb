{"cells":[{"cell_type":"markdown","id":"a15a141a-ff00-48ea-856f-1ca32fae1ea4","metadata":{},"outputs":[],"source":["\n","<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n","\n","\n","# K-Means Clustering\n","\n","\n","Estimated time needed: **25** minutes\n","    \n","\n","## Objectives\n","\n","After completing this lab you will be able to:\n","\n","* Use scikit-learn's K-Means Clustering to cluster data\n"]},{"cell_type":"markdown","id":"b6facf23-cb0a-4318-a8da-93a161ef5298","metadata":{},"outputs":[],"source":["## Introduction\n","\n","There are many models for **clustering** out there. In this notebook, we will be presenting the model that is considered one of the simplest models amongst them. Despite its simplicity, the **K-means** is vastly used for clustering in many data science applications, it is especially useful if you need to quickly discover insights from **unlabeled data**. In this notebook, you will learn how to use k-Means for customer segmentation.\n","\n","Some real-world applications of k-means:\n","- Customer segmentation\n","- Understand what the visitors of a website are trying to accomplish\n","- Pattern recognition\n","- Machine learning\n","- Data compression\n","\n","\n","In this notebook we practice k-means clustering with 2 examples:\n","- k-means on a random generated dataset\n","- Using k-means for customer segmentation\n"]},{"cell_type":"markdown","id":"e22316ed-f616-4bdb-9de4-5e50174e3c39","metadata":{},"outputs":[],"source":["<h1>Table of contents</h1>\n","\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","    <ul>\n","        <li><a href=\"#random_generated_dataset\">k-Means on a randomly generated dataset</a></li>\n","            <ol>\n","                <li><a href=\"#setting_up_K_means\">Setting up K-Means</a></li>\n","                <li><a href=\"#creating_visual_plot\">Creating the Visual Plot</a></li>\n","            </ol>\n","        <p></p>\n","        <li><a href=\"#customer_segmentation_K_means\">Customer Segmentation with K-Means</a></li>\n","            <ol>\n","                <li><a href=\"#pre_processing\">Pre-processing</a></li>\n","                <li><a href=\"#modeling\">Modeling</a></li>\n","                <li><a href=\"#insights\">Insights</a></li>\n","            </ol>\n","    </ul>\n","</div>\n","<br>\n","<hr>\n"]},{"cell_type":"markdown","id":"02c506a6-a70a-44db-b0ef-6e33f00e9ce9","metadata":{},"outputs":[],"source":["### Import libraries\n","Let's first import the required libraries.\n","Also run <b> %matplotlib inline </b> since we will be plotting in this section.\n"]},{"cell_type":"code","id":"791f5d04-0648-4d45-81db-e9ce74d0367a","metadata":{},"outputs":[],"source":["# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn"]},{"cell_type":"code","id":"d72efc0f-67b5-452b-bfcd-f96440a9f52f","metadata":{},"outputs":[],"source":["!pip install scikit-learn\n!pip install matplotlib\n!pip install pandas \n!pip install numpy \n%matplotlib inline"]},{"cell_type":"code","id":"18b519bc-9296-48be-aafc-71480003b8c5","metadata":{},"outputs":[],"source":["import random \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.cluster import KMeans \nfrom sklearn.datasets import make_blobs \n%matplotlib inline"]},{"cell_type":"markdown","id":"88a06f0a-eaff-4448-bd8d-142a22181a5e","metadata":{},"outputs":[],"source":["<h1 id=\"random_generated_dataset\">k-Means on a randomly generated dataset</h1>\n","\n","Let's create our own dataset for this lab!\n"]},{"cell_type":"markdown","id":"b8145d25-c37f-4080-9945-860359449c14","metadata":{},"outputs":[],"source":["First we need to set a random seed. Use <b>numpy's random.seed()</b> function, where the seed will be set to <b>0</b>.\n"]},{"cell_type":"code","id":"a9223a9c-e4a0-407f-b2ba-6c832024ac8c","metadata":{},"outputs":[],"source":["np.random.seed(0)"]},{"cell_type":"markdown","id":"f60b4f64-6ca2-4a9d-84a5-b695595a5f5c","metadata":{},"outputs":[],"source":["Next we will be making <i> random clusters </i> of points by using the <b> make_blobs </b> class. The <b> make_blobs </b> class can take in many inputs, but we will be using these specific ones. <br> <br>\n","<b> <u> Input </u> </b>\n","<ul>\n","    <li> <b>n_samples</b>: The total number of points equally divided among clusters. </li>\n","    <ul> <li> Value will be: 5000 </li> </ul>\n","    <li> <b>centers</b>: The number of centers to generate, or the fixed center locations. </li>\n","    <ul> <li> Value will be: [[4, 4], [-2, -1], [2, -3],[1,1]] </li> </ul>\n","    <li> <b>cluster_std</b>: The standard deviation of the clusters. </li>\n","    <ul> <li> Value will be: 0.9 </li> </ul>\n","</ul>\n","<br>\n","<b> <u> Output </u> </b>\n","<ul>\n","    <li> <b>X</b>: Array of shape [n_samples, n_features]. (Feature Matrix)</li>\n","    <ul> <li> The generated samples. </li> </ul> \n","    <li> <b>y</b>: Array of shape [n_samples]. (Response Vector)</li>\n","    <ul> <li> The integer labels for cluster membership of each sample. </li> </ul>\n","</ul>\n"]},{"cell_type":"code","id":"ca82888a-0d1e-40ee-bd0e-fb28baef296d","metadata":{},"outputs":[],"source":["X, y = make_blobs(n_samples=5000, centers=[[4,4], [-2, -1], [2, -3], [1, 1]], cluster_std=0.9)"]},{"cell_type":"markdown","id":"0203347e-fa0f-441b-bc17-4c83133c75f1","metadata":{},"outputs":[],"source":["Display the scatter plot of the randomly generated data.\n"]},{"cell_type":"code","id":"7a30230b-f98a-43a8-becf-8b46ee3a2f09","metadata":{},"outputs":[],"source":["plt.scatter(X[:, 0], X[:, 1], marker='.')"]},{"cell_type":"markdown","id":"67893ac3-2ef1-4745-9403-4c4c9b253e65","metadata":{},"outputs":[],"source":["<h2 id=\"setting_up_K_means\">Setting up K-Means</h2>\n","Now that we have our random data, let's set up our K-Means Clustering.\n"]},{"cell_type":"markdown","id":"02b72caa-625e-4e11-82b8-932c52933c0e","metadata":{},"outputs":[],"source":["The KMeans class has many parameters that can be used, but we will be using these three:\n","<ul>\n","    <li> <b>init</b>: Initialization method of the centroids. </li>\n","    <ul>\n","        <li> Value will be: \"k-means++\" </li>\n","        <li> k-means++: Selects initial cluster centers for k-mean clustering in a smart way to speed up convergence.</li>\n","    </ul>\n","    <li> <b>n_clusters</b>: The number of clusters to form as well as the number of centroids to generate. </li>\n","    <ul> <li> Value will be: 4 (since we have 4 centers)</li> </ul>\n","    <li> <b>n_init</b>: Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia. </li>\n","    <ul> <li> Value will be: 12 </li> </ul>\n","</ul>\n","\n","Initialize KMeans with these parameters, where the output parameter is called <b>k_means</b>.\n"]},{"cell_type":"code","id":"b62608fc-1eb7-4319-9c35-5a0248c29492","metadata":{},"outputs":[],"source":["k_means = KMeans(init = \"k-means++\", n_clusters = 4, n_init = 12)"]},{"cell_type":"markdown","id":"10040971-ea47-403e-a433-8ca38d2a3ac0","metadata":{},"outputs":[],"source":["Now let's fit the KMeans model with the feature matrix we created above, <b> X </b>.\n"]},{"cell_type":"code","id":"52a97aa8-4359-4236-8877-64e2d5ed3341","metadata":{},"outputs":[],"source":["k_means.fit(X)"]},{"cell_type":"markdown","id":"a5bf34ce-820d-461e-b5dc-b681bc22b473","metadata":{},"outputs":[],"source":["Now let's grab the labels for each point in the model using KMeans' <b> .labels\\_ </b> attribute and save it as <b> k_means_labels </b>.\n"]},{"cell_type":"code","id":"d55fe472-3269-46c9-8077-037ad8db2e78","metadata":{},"outputs":[],"source":["k_means_labels = k_means.labels_\nk_means_labels"]},{"cell_type":"markdown","id":"c6ecd313-8793-4eb0-bb3a-c4233db9d0e9","metadata":{},"outputs":[],"source":["We will also get the coordinates of the cluster centers using KMeans' <b> .cluster&#95;centers&#95; </b> and save it as <b> k_means_cluster_centers </b>.\n"]},{"cell_type":"code","id":"2169e5a5-9935-4489-961c-19535f2b5c6f","metadata":{},"outputs":[],"source":["k_means_cluster_centers = k_means.cluster_centers_\nk_means_cluster_centers"]},{"cell_type":"markdown","id":"0296f0bf-5df1-48c0-bd5c-3f6c67ac3049","metadata":{},"outputs":[],"source":["<h2 id=\"creating_visual_plot\">Creating the Visual Plot</h2>\n","\n","So now that we have the random data generated and the KMeans model initialized, let's plot them and see what it looks like!\n"]},{"cell_type":"markdown","id":"696ae966-797c-40b7-bc17-470d59e799f3","metadata":{},"outputs":[],"source":["Please read through the code and comments to understand how to plot the model.\n"]},{"cell_type":"code","id":"9da0bb03-47fb-4e1e-9eaa-522d9e84bca4","metadata":{},"outputs":[],"source":["# Initialize the plot with the specified dimensions.\nfig = plt.figure(figsize=(6, 4))\n\n# Colors uses a color map, which will produce an array of colors based on\n# the number of labels there are. We use set(k_means_labels) to get the\n# unique labels.\ncolors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means_labels))))\n\n# Create a plot\nax = fig.add_subplot(1, 1, 1)\n\n# For loop that plots the data points and centroids.\n# k will range from 0-3, which will match the possible clusters that each\n# data point is in.\nfor k, col in zip(range(len([[4,4], [-2, -1], [2, -3], [1, 1]])), colors):\n\n    # Create a list of all data points, where the data points that are \n    # in the cluster (ex. cluster 0) are labeled as true, else they are\n    # labeled as false.\n    my_members = (k_means_labels == k)\n    \n    # Define the centroid, or cluster center.\n    cluster_center = k_means_cluster_centers[k]\n    \n    # Plots the datapoints with color col.\n    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n    \n    # Plots the centroids with specified color, but with a darker outline\n    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)\n\n# Title of the plot\nax.set_title('KMeans')\n\n# Remove x-axis ticks\nax.set_xticks(())\n\n# Remove y-axis ticks\nax.set_yticks(())\n\n# Show the plot\nplt.show()\n"]},{"cell_type":"markdown","id":"3042931c-150b-4d76-9b12-830dfb896468","metadata":{},"outputs":[],"source":["## Practice\n","Try to cluster the above dataset into 3 clusters.  \n","Notice: do not generate the data again, use the same dataset as above.\n"]},{"cell_type":"code","id":"7b21058f-a631-41b9-9970-2bdc5d9714d8","metadata":{},"outputs":[],"source":["# write your code here\n"]},{"cell_type":"markdown","id":"a15aa430-fb89-4926-889b-1bb5eb0d8651","metadata":{},"outputs":[],"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","k_means3 = KMeans(init = \"k-means++\", n_clusters = 3, n_init = 12)\n","k_means3.fit(X)\n","fig = plt.figure(figsize=(6, 4))\n","colors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means3.labels_))))\n","ax = fig.add_subplot(1, 1, 1)\n","for k, col in zip(range(len(k_means3.cluster_centers_)), colors):\n","    my_members = (k_means3.labels_ == k)\n","    cluster_center = k_means3.cluster_centers_[k]\n","    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n","    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)\n","plt.show()\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"e666ed9b-b46a-454d-81bb-f534989d191c","metadata":{},"outputs":[],"source":["<h1 id=\"customer_segmentation_K_means\">Customer Segmentation with K-Means</h1>\n","\n","Imagine that you have a customer dataset, and you need to apply customer segmentation on this historical data.\n","Customer segmentation is the practice of partitioning a customer base into groups of individuals that have similar characteristics. It is a significant strategy as a business can target these specific groups of customers and effectively allocate marketing resources. For example, one group might contain customers who are high-profit and low-risk, that is, more likely to purchase products, or subscribe for a service. A business task is to retain those customers. Another group might include customers from non-profit organizations and so on.\n"]},{"cell_type":"markdown","id":"7b0af35e-d0f5-485e-b998-126e4ecd5082","metadata":{},"outputs":[],"source":["### Load Data From CSV File  \n","Before you can work with the data, let's use pandas to read the dataset from IBM Object Storage.\n"]},{"cell_type":"code","id":"7cc04eef-fb01-40e6-8027-c604bf664e76","metadata":{},"outputs":[],"source":["import pandas as pd\ncust_df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%204/data/Cust_Segmentation.csv\")\ncust_df.head()"]},{"cell_type":"markdown","id":"b96f1b98-04d9-49e8-b0a2-48681427ad57","metadata":{},"outputs":[],"source":["<h2 id=\"pre_processing\">Pre-processing</h2\n"]},{"cell_type":"markdown","id":"c4bfe7ea-a0b8-4be0-ba9b-6b13fd782cb1","metadata":{},"outputs":[],"source":["As you can see, __Address__ in this dataset is a categorical variable. The k-means algorithm isn't directly applicable to categorical variables because the Euclidean distance function isn't really meaningful for discrete variables. So, let's drop this feature and run clustering.\n"]},{"cell_type":"code","id":"e6294a0d-02fa-4e7f-9843-c05e76419892","metadata":{},"outputs":[],"source":["df = cust_df.drop('Address', axis=1)\ndf.head()"]},{"cell_type":"markdown","id":"f422ab33-b2bd-4b6a-b94e-8428a850998f","metadata":{},"outputs":[],"source":["#### Normalizing over the standard deviation\n","Now let's normalize the dataset. But why do we need normalization in the first place? Normalization is a statistical method that helps mathematical-based algorithms to interpret features with different magnitudes and distributions equally. We use __StandardScaler()__ to normalize our dataset.\n"]},{"cell_type":"code","id":"cb14e204-9e37-4226-943b-a74537dd4830","metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\nX = df.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet = StandardScaler().fit_transform(X)\nClus_dataSet"]},{"cell_type":"markdown","id":"8ff47476-3274-445b-8c81-f65530123a0a","metadata":{},"outputs":[],"source":["<h2 id=\"modeling\">Modeling</h2>\n"]},{"cell_type":"markdown","id":"49d3fe36-ddaa-4846-931b-80ced4cb17db","metadata":{},"outputs":[],"source":["In our example (if we didn't have access to the k-means algorithm), it would be the same as guessing that each customer group would have certain age, income, education, etc, with multiple tests and experiments. However, using the K-means clustering we can do all this process much easier.\n","\n","Let's apply k-means on our dataset, and take a look at cluster labels.\n"]},{"cell_type":"code","id":"0e3b9b9d-00bf-416c-928b-092049658b81","metadata":{},"outputs":[],"source":["clusterNum = 3\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(X)\nlabels = k_means.labels_\nprint(labels)"]},{"cell_type":"markdown","id":"a549636f-c54f-4cd6-a44e-ec891a29c228","metadata":{},"outputs":[],"source":["<h2 id=\"insights\">Insights</h2>\n","\n","We assign the labels to each row in the dataframe.\n"]},{"cell_type":"code","id":"0891e105-0468-4485-8598-d72b04a31967","metadata":{},"outputs":[],"source":["df[\"Clus_km\"] = labels\ndf.head(5)"]},{"cell_type":"markdown","id":"65b357d7-1a36-4112-acff-b4f12e24ae2b","metadata":{},"outputs":[],"source":["We can easily check the centroid values by averaging the features in each cluster.\n"]},{"cell_type":"code","id":"9b82c435-c0b1-49a9-8802-793a6359405a","metadata":{},"outputs":[],"source":["df.groupby('Clus_km').mean()"]},{"cell_type":"markdown","id":"bbcd6097-0a3a-4ccf-a7af-fa81065e41d5","metadata":{},"outputs":[],"source":["Now, let's look at the distribution of customers based on their age and income:\n"]},{"cell_type":"code","id":"897c1ee0-0389-468c-892f-c17995248bef","metadata":{},"outputs":[],"source":["area = np.pi * (X[:, 1])**2  \nplt.scatter(X[:, 0], X[:, 3], s=area, c=labels.astype(float), alpha=0.5)  # Use built-in 'float'\nplt.xlabel('Age', fontsize=18)\nplt.ylabel('Income', fontsize=16)\n\nplt.show()\n"]},{"cell_type":"code","id":"e0a59c1a-c0f7-44fb-a917-9ce416102af6","metadata":{},"outputs":[],"source":["from mpl_toolkits.mplot3d import Axes3D \nfig = plt.figure(1, figsize=(8, 6))\nplt.clf()\nax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n\nplt.cla()\n# plt.ylabel('Age', fontsize=18)\n# plt.xlabel('Income', fontsize=16)\n# plt.zlabel('Education', fontsize=16)\nax.set_xlabel('Education')\nax.set_ylabel('Age')\nax.set_zlabel('Income')\n\nax.scatter(X[:, 1], X[:, 0], X[:, 3], c= labels.astype(np.float))\n"]},{"cell_type":"markdown","id":"6e65a14a-7e4a-4120-83d7-fa53feb25db8","metadata":{},"outputs":[],"source":["k-means will partition your customers into mutually exclusive groups, for example, into 3 clusters. The customers in each cluster are similar to each other demographically.\n","Now we can create a profile for each group, considering the common characteristics of each cluster. \n","For example, the 3 clusters can be:\n","\n","- AFFLUENT, EDUCATED AND OLD AGED\n","- MIDDLE AGED AND MIDDLE INCOME\n","- YOUNG AND LOW INCOME\n"]},{"cell_type":"markdown","id":"7088620b-b6f4-4f89-8d7e-539f8c73eb03","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","\n","## Author\n","\n","Saeed Aghabozorgi\n","\n","\n","### Other Contributors\n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\" target=\"_blank\">Joseph Santarcangelo</a>\n","\n","## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n","\n","<!--\n","## Change Log\n","\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-11-03  | 2.1  | Lakshmi  |  Updated URL of csv |\n","| 2020-08-27  | 2.0  | Lavanya  |  Moved lab to course repo in GitLab |\n","|   |   |   |   |\n","|   |   |   |   |\n","--!>\n","\n","\n"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.11.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"4df33031d11021d2e7884da94a044ed0b47ee3cae2f1461d687e98085b7238c0"},"nbformat":4,"nbformat_minor":4}